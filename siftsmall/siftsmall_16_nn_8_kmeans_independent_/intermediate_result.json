{"total_time_consume": 60.40388059616089, "preprocess": {"total_time": 0.3119385242462158}, "classifier": [{"ins_id": 0, "dataset_partition": {"kmeans_time": 11.86209511756897, "total_time": 11.863160133361816, "cluster_number_distribution": [751, 502, 656, 597, 657, 366, 679, 498, 516, 757, 602, 593, 880, 655, 581, 710]}, "prepare_train_sample": {"time": 0.06725955009460449}, "train_eval_model": {"train_intermediate": [{"epoch": 0, "loss": 62.42658127815493, "eval_loss": 42.01405143737793, "train_recall": 0.7688888888888888, "val_recall": 0.82, "lr": 0.008}, {"epoch": 1, "loss": 57.498059205086, "eval_loss": 40.722025871276855, "train_recall": 0.8064646464646464, "val_recall": 0.82, "lr": 0.008}], "train_total": {"correct": 7984, "final_recall": 0.8064646464646464}, "training_time": 3.813079833984375, "eval_time": 0.003622293472290039}}, {"ins_id": 1, "dataset_partition": {"kmeans_time": 2.6533360481262207, "total_time": 2.6544342041015625, "cluster_number_distribution": [650, 615, 578, 517, 766, 622, 710, 747, 702, 695, 616, 382, 449, 986, 451, 514]}, "prepare_train_sample": {"time": 0.010627031326293945}, "train_eval_model": {"train_intermediate": [{"epoch": 0, "loss": 61.4605238391507, "eval_loss": 41.25544452667236, "train_recall": 0.7687878787878788, "val_recall": 0.87, "lr": 0.008}, {"epoch": 1, "loss": 56.28091253465222, "eval_loss": 38.71004772186279, "train_recall": 0.8114141414141414, "val_recall": 0.9, "lr": 0.008}], "train_total": {"correct": 8033, "final_recall": 0.8114141414141414}, "training_time": 3.593013048171997, "eval_time": 0.004061222076416016}}, {"ins_id": 2, "dataset_partition": {"kmeans_time": 2.554882287979126, "total_time": 2.556074380874634, "cluster_number_distribution": [590, 686, 502, 668, 618, 600, 505, 720, 561, 746, 653, 636, 877, 598, 505, 535]}, "prepare_train_sample": {"time": 0.010091066360473633}, "train_eval_model": {"train_intermediate": [{"epoch": 0, "loss": 62.552677572927166, "eval_loss": 42.27743339538574, "train_recall": 0.7640404040404041, "val_recall": 0.82, "lr": 0.008}, {"epoch": 1, "loss": 57.6463134765625, "eval_loss": 41.23705577850342, "train_recall": 0.8038383838383838, "val_recall": 0.85, "lr": 0.008}], "train_total": {"correct": 7958, "final_recall": 0.8038383838383838}, "training_time": 3.347867965698242, "eval_time": 0.0033485889434814453}}, {"ins_id": 3, "dataset_partition": {"kmeans_time": 2.298539400100708, "total_time": 2.2997236251831055, "cluster_number_distribution": [712, 734, 548, 599, 578, 441, 862, 625, 594, 626, 507, 750, 521, 873, 468, 562]}, "prepare_train_sample": {"time": 0.01871347427368164}, "train_eval_model": {"train_intermediate": [{"epoch": 0, "loss": 62.5249624683011, "eval_loss": 46.02690601348877, "train_recall": 0.7676767676767676, "val_recall": 0.82, "lr": 0.008}, {"epoch": 1, "loss": 57.56907316638577, "eval_loss": 40.60201168060303, "train_recall": 0.804040404040404, "val_recall": 0.87, "lr": 0.008}], "train_total": {"correct": 7960, "final_recall": 0.804040404040404}, "training_time": 3.5554704666137695, "eval_time": 0.0034177303314208984}}, {"ins_id": 4, "dataset_partition": {"kmeans_time": 2.404304027557373, "total_time": 2.405478000640869, "cluster_number_distribution": [697, 576, 1005, 518, 697, 567, 743, 474, 359, 493, 573, 574, 695, 712, 513, 804]}, "prepare_train_sample": {"time": 0.009166240692138672}, "train_eval_model": {"train_intermediate": [{"epoch": 0, "loss": 61.335611552576864, "eval_loss": 40.912588119506836, "train_recall": 0.7627272727272727, "val_recall": 0.84, "lr": 0.008}, {"epoch": 1, "loss": 55.75842595254221, "eval_loss": 40.546664237976074, "train_recall": 0.8082828282828283, "val_recall": 0.77, "lr": 0.008}], "train_total": {"correct": 8002, "final_recall": 0.8082828282828283}, "training_time": 3.5158965587615967, "eval_time": 0.003266572952270508}}, {"ins_id": 5, "dataset_partition": {"kmeans_time": 2.3567001819610596, "total_time": 2.3576481342315674, "cluster_number_distribution": [551, 312, 466, 682, 1058, 771, 391, 536, 622, 576, 553, 878, 634, 833, 663, 474]}, "prepare_train_sample": {"time": 0.008460760116577148}, "train_eval_model": {"train_intermediate": [{"epoch": 0, "loss": 61.26714726109658, "eval_loss": 37.42032814025879, "train_recall": 0.7507070707070707, "val_recall": 0.87, "lr": 0.008}, {"epoch": 1, "loss": 55.622384766609436, "eval_loss": 37.25654697418213, "train_recall": 0.7895959595959596, "val_recall": 0.86, "lr": 0.008}], "train_total": {"correct": 7817, "final_recall": 0.7895959595959596}, "training_time": 3.4731006622314453, "eval_time": 0.0037078857421875}}, {"ins_id": 6, "dataset_partition": {"kmeans_time": 2.4144179821014404, "total_time": 2.4155118465423584, "cluster_number_distribution": [552, 616, 582, 659, 779, 753, 578, 597, 739, 807, 892, 354, 500, 508, 564, 520]}, "prepare_train_sample": {"time": 0.008156299591064453}, "train_eval_model": {"train_intermediate": [{"epoch": 0, "loss": 62.43782794091009, "eval_loss": 41.33993721008301, "train_recall": 0.7688888888888888, "val_recall": 0.82, "lr": 0.008}, {"epoch": 1, "loss": 56.781631937334616, "eval_loss": 40.4407262802124, "train_recall": 0.8095959595959596, "val_recall": 0.79, "lr": 0.008}], "train_total": {"correct": 8015, "final_recall": 0.8095959595959596}, "training_time": 3.485567569732666, "eval_time": 0.003415822982788086}}, {"ins_id": 7, "dataset_partition": {"kmeans_time": 2.434227228164673, "total_time": 2.435363292694092, "cluster_number_distribution": [596, 724, 667, 405, 559, 672, 714, 566, 584, 514, 878, 711, 469, 553, 765, 623]}, "prepare_train_sample": {"time": 0.009787559509277344}, "train_eval_model": {"train_intermediate": [{"epoch": 0, "loss": 62.52865482453377, "eval_loss": 41.37670707702637, "train_recall": 0.7628282828282829, "val_recall": 0.9, "lr": 0.008}, {"epoch": 1, "loss": 57.72154267834079, "eval_loss": 39.983201026916504, "train_recall": 0.8076767676767677, "val_recall": 0.87, "lr": 0.008}], "train_total": {"correct": 7996, "final_recall": 0.8076767676767677}, "training_time": 3.3231356143951416, "eval_time": 0.003348827362060547}}], "integrate": {"time": 2.21767258644104}, "count_recall": {"time": 0.38335108757019043}}